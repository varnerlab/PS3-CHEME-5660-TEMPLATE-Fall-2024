{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaf9a18-36cb-42b6-860c-af14e050cac6",
   "metadata": {},
   "source": [
    "# Problem Set 3: Probability of Profit Calculations for Lattice versus Geometric Brownian Motion\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3abbd-8899-43a3-8242-1de71fc739c7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include.jl` file](Include.jl). The [`Include.jl` file](Include.jl) loads external packages, various functions that we will use in the exercise, and custom types to model the components of our example problem.\n",
    "* See the [Julia programming language documentation](https://docs.julialang.org/en/v1/) and the [VLQuantitativeFinancePackage.jl documentation](https://github.com/varnerlab/VLQuantitativeFinancePackage.jl) for additional information on functions and types used in this material. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01886a45-e486-42e8-b8f5-df53a0e59c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b5978-a13f-4302-b635-0925f3dc737f",
   "metadata": {},
   "source": [
    "## Prerequisites: Load and clean the testing dataset\n",
    "\n",
    "#### Out of Sample Data\n",
    "We gathered a daily open-high-low-close `dataset` for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) from `01-03-2024` until last week `09-23-24` close, along with data for a few exchange-traded funds and volatility products during that time. We load the `prediction_dataset` by calling the `MyOutOfSampleMarketDataSet()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38540e26-12bf-4bef-8999-dba85dbb43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset = MyOutOfSampleMarketDataSet() |> x-> x[\"dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b184816-1c80-4ba8-a8c1-294a600a548d",
   "metadata": {},
   "source": [
    "Next, let's get a list of firms in the `prediction_dataset,` and save it in the `list_of_all_tickers::String` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e46bb-a41f-4ea2-a2cb-3cff1d851148",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_tickers = keys(prediction_dataset) |> collect |> sort;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597dbe25-1948-48fb-8194-23a5423831a8",
   "metadata": {},
   "source": [
    "#### Lattice parameters\n",
    "We saved the real-world and risk-neutral lattice parameter calculations, so let's load this save file to construct our lattice model. To load the `jld2` (binary) saved file, we pass the path to the file we want to load the [`load(...)` function](https://github.com/JuliaIO/FileIO.jl). This call returns the data as a [Julia `Dict` type](https://docs.julialang.org/en/v1/base/collections/#Base.Dict). \n",
    "* Let's set the path to the save file in the `path_to_lattice_save_file::String` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b3a91-6d36-4f7b-8ee2-d58d31693bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_lattice_save_file = joinpath(_PATH_TO_DATA, \"L5a-RealWorldRiskNeutral-SavedData.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c719fa-41ec-44c5-b9d3-ecbf6215293b",
   "metadata": {},
   "source": [
    "Then we load the `jld2` file using [the `load(...)` method](https://juliaio.github.io/FileIO.jl/stable/reference/#FileIO.load), where the contents of the file are stored in the `saved_data_dictionary::Dict{String, Any}` variable. \n",
    "* In particular, we pull out the `real_world_parameters::Dict{String, Tuple{Float64, Float64, Float64}}` dictionary that holds the real-world parameters estimated previously. This will have $(u,d,p)$ values for each ticker in the clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ddb4f-1e2b-4368-a9fb-85efb43b5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data_dictionary = load(path_to_lattice_save_file); # saved data as a dictionary\n",
    "real_world_parameters = saved_data_dictionary[\"real_world_parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44588e-b131-497e-a165-fd6697b92d54",
   "metadata": {},
   "source": [
    "#### GBM parameters\n",
    "Finally, we saved the estimated real-world GBM model parameters using data from 2018 to 2023, so let's load the saved parameter file to initialize our GBM model.\n",
    "* Load the $(\\hat{\\mu},\\hat{\\sigma})$ dataset we computed previously [using `read(...)` method exported by the CSV.jl package](https://github.com/JuliaData/CSV.jl) and store this in the `parameters_df::DataFrame` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb418fd-d6d2-46df-81dd-e945a0757758",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_df = CSV.read(joinpath(_PATH_TO_DATA,\"Parameters-SP500-2018-2023-Backup.csv\"), DataFrame);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918f2fc-068e-4f60-8552-2ec002f681d8",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "Let's set some constants we'll use later in this notebook. The comments describe the constants, the units, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af0617-0a2e-4f46-b5a9-bd33b75e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt = (1.0/252); # step size: 1-trading day in units of years\n",
    "risk_free_rate = 0.0; # hypothetical continuously compounding risk-free rate\n",
    "simulation_start_index = 1; # start the first day of the OOS data\n",
    "simulation_stop_index = 62; # end the last day of OOS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c019d-be30-4db1-93b6-cf9ef7a59704",
   "metadata": {},
   "source": [
    "## Task 1: Build a collection of binomial lattice models\n",
    "In this task, we'll try to build and populate a lattice model _for each asset_ in the `list_of_all_tickers::Array{String,1}`, i.e., for every ticker in the out-of-sample dataset. We'll store these models in the `lattice_model_dictionary::Dict{String, MyBinomialEquityPriceTree}` dictionary.\n",
    "\n",
    "#### Strategy\n",
    "* Iterate through each ticker in the `list_of_all_tickers::Array{String,1}` array, get the $(u,d,p)$ lattice parameters from the `parameters_df::Dict{String, Tuple{Float64, Float64, Float64}}` dictionary, and build [a `MyBinomialEquityPriceTree` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MyBinomialEquityPriceTree) using [the appropriate `build(...)` method](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MyBinomialEquityPriceTree},%20NamedTuple}).\n",
    "* The out-of-sample data has additional tickers, so we'll only build and populate models for which we have parameter data. In a lecture example, we've shown one way to do this. Alternatively, [check out the `haskey(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.haskey) which can be used to check if a dictionary has a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4a8bb-0471-4735-afdf-e7d249fe7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_model_dictionary = let\n",
    "\n",
    "    lattice_model_dictionary = Dict{String, MyBinomialEquityPriceTree}(); # initialize storage\n",
    "    for ticker ∈ list_of_all_tickers\n",
    "\n",
    "        if (haskey(real_world_parameters, ticker) == true) # only build a model for which we have data\n",
    "\n",
    "            # get lattice parameters\n",
    "            u = real_world_parameters[ticker][1];\n",
    "            d = real_world_parameters[ticker][2];\n",
    "            p = real_world_parameters[ticker][3];\n",
    "\n",
    "            # build -\n",
    "            lattice_model_dictionary[ticker] = build(MyBinomialEquityPriceTree, (\n",
    "                u = u, d = d, p = p));\n",
    "        end\n",
    "    end\n",
    "\n",
    "    lattice_model_dictionary;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695e5be-a43c-4de4-946e-e6a3dc9b751f",
   "metadata": {},
   "source": [
    "Now that we the collection of lattice models, let's do something similar in spirit for the geometric Brownian motion models in task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3b876-b019-427a-a429-f097a0583531",
   "metadata": {},
   "source": [
    "## Task 2: Build a collection of geometric Brownian motion models\n",
    "In this task, we'll try to build and populate a geometric Brownian motion (GBM) model _for each asset_ in the `list_of_all_tickers::Array{String,1}`, i.e., for every ticker in the out-of-sample dataset. We'll store these models in the `gbm_model_dictionary::Dict{String, MyGeometricBrownianMotionEquityModel}` dictionary.\n",
    "\n",
    "#### Strategy\n",
    "* Iterate through each ticker in the `list_of_all_tickers::Array{String,1}` array, get the $(\\hat{\\mu},\\hat{\\sigma})$ gbm parameters from the `parameters_df::Dict{String, DataFrame}` dictionary, and then build [a `MyGeometricBrownianMotionEquityModel` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.MyGeometricBrownianMotionEquityModel) using a [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MyGeometricBrownianMotionEquityModel},%20NamedTuple}), where you pass in values for the $(\\hat{\\mu},\\hat{\\sigma})$ parameters as arguments to the [build function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.build-Tuple{Type{MyGeometricBrownianMotionEquityModel},%20NamedTuple}).\n",
    "* The out-of-sample data has additional tickers, so we'll only build and populate models for which we have parameter data. In a lecture example, we've shown one way to do this. Alternatively, [check out the `haskey(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.haskey) which can be used to check if a dictionary has a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda0553-1da9-4f34-9450-b9f68cb824d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model_dictionary = let\n",
    "\n",
    "    gbm_model_dictionary = Dict{String, MyGeometricBrownianMotionEquityModel}(); # initialize storage\n",
    "    training_ticker_list = parameters_df[:,:ticker]; # get's list of tickers in the training data set\n",
    "    for ticker ∈ list_of_all_tickers\n",
    "\n",
    "        if (ticker ∈ training_ticker_list) # only build a model for which we have data\n",
    "\n",
    "            my_parameters = findfirst(x->x==ticker, parameters_df[:,:ticker]) |> i-> parameters_df[i,:];\n",
    "            μ̂ = my_parameters[:drift]; # drift parameter\n",
    "            σ̂ = my_parameters[:volatility]; # volatility parameter\n",
    "\n",
    "            gbm_model_dictionary[ticker] = build(MyGeometricBrownianMotionEquityModel, (\n",
    "                μ = μ̂, σ = σ̂ ));\n",
    "        end\n",
    "    end\n",
    "\n",
    "    gbm_model_dictionary;    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245260f0-6050-4d06-8391-57f206d681df",
   "metadata": {},
   "source": [
    "Now that we have both the lattice and gbm models, we can now compare probability of profit calculations for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7289cd-b7fb-44fe-ab83-70fdbb650400",
   "metadata": {},
   "source": [
    "## Task 3: Estimate the probability of profit using the different model types\n",
    "In this task, we'll compare the cumulative distribution curves, which we use to estimate the probability of profit, computed using a lattice model versus a gbm model. To start, let's specify a ticker (contained in both the training and out-of-sample prediction datasets) in the `my_ticker_of_interest::String` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6a45b-2b33-4146-9d9f-21b0bda68acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ticker_of_interest = \"GS\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8be010-4db2-468a-896b-bd200a757e46",
   "metadata": {},
   "source": [
    "### Cumulative distribution lattice model\n",
    "Next, we estimate the cumulative distribution function for the lattice model. To do this, we must first populate the lattice tree for `my_ticker_of_interest::String.`\n",
    "* We populate a lattice model tree [using the `populate(...)` method](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.populate-Tuple{MyBinomialEquityPriceTree}). We start the simulation on `simulation_start_index::Int64` and end on `simulation_stop_index::Int64`. We access the starting price of the asset of interest from the `prediction_dataset::Dict{String, DataFrame}.` Let's use the [volume weighted average price (vwap)](https://en.wikipedia.org/wiki/Volume-weighted_average_price) to initialize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d7129-1790-4917-8a44-a33de0ecb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "populated_tree_model = let\n",
    "    L = simulation_stop_index; # how many levels\n",
    "    Sₒ = prediction_dataset[my_ticker_of_interest][simulation_start_index, :volume_weighted_average_price]; # start price\n",
    "    model = lattice_model_dictionary[my_ticker_of_interest] |> model -> populate(model, Sₒ = Sₒ, h = L);\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73150b7f-494b-41a6-89d6-c334d7b19456",
   "metadata": {},
   "source": [
    "Get the collection of nodes of [type `MyBiomialLatticeEquityNodeModel,`]() using the short-cut syntax `(tree::MyBinomialEquityPriceTree)(level::Int64)`, which returns the collection of nodes at `level = t.` Store the tree nodes at `level=simulation_stop_index` in the `leaves` array\n",
    "* The short-cut syntax for accessing the tree nodes is equivalent to the command sequence: `tree.levels[level] .|> x-> tree.data[x].` If you'd like to see how we make a type callable, this logic is encoded in the [Compute.jl](src/Compute.jl) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e31404-943b-4296-a883-985aa3933b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = populated_tree_model(simulation_stop_index);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381f756-1f1d-44ae-9601-6c9bde04f58c",
   "metadata": {},
   "source": [
    "Now that we have computed the share price and the probability of the share price, we can sample the nodes of the binomial tree at `level=simulation_stop_index` using a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) initialized with the probability of each node at `level = simulation_stop_index.` \n",
    "* From this data, we can approximate the [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function) for the fractional return, i.e., the probability that the fractional return will be less than some specified (desired) value, i.e., breakeven.\n",
    "* A [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) is a type of probability distribution that describes the possible outcomes of a random variable that can belong to one of `K` categories. In this case, the `K`-categories correspond to indexes of the nodes in the tree at `level = simulation_stop_index`\n",
    "* Let's create a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) using the probabilities of our equity share prices on the leaves of the tree using the [Distributions.jl](https://github.com/JuliaStats/Distributions.jl) package. Save the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) in the `dcat` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec940489-c9e7-4207-9d3a-9f74a6029f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_probability_array = let\n",
    "    \n",
    "    leaf_probability_array = Array{Float64,1}();\n",
    "    for leaf ∈ leaves\n",
    "        p = leaf.probability;\n",
    "        push!(leaf_probability_array,p);\n",
    "    end\n",
    "    leaf_probability_array;\n",
    "end\n",
    "dcat = Categorical(leaf_probability_array); # catagorical distribution for each node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003655f1-47d4-4c37-ad01-4546054aaf98",
   "metadata": {},
   "source": [
    "Next, let's create the `minimum_return_target_array,` which holds the fractional returns calculated from the prices of the leaves of the binomial tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1d198-8891-4f90-ae83-6f3d5305b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_return_target_array = let\n",
    "\n",
    "    minimum_return_target_array = Array{Float64,1}();\n",
    "    Sₒ = prediction_dataset[my_ticker_of_interest][simulation_start_index, :volume_weighted_average_price]; # start price\n",
    "    for leaf ∈ leaves\n",
    "        price = leaf.price;\n",
    "        f = (price - Sₒ)/Sₒ;\n",
    "        push!(minimum_return_target_array, f);\n",
    "    end\n",
    "    minimum_return_target_array;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c6560-5933-45d4-9f79-dd26e973b2af",
   "metadata": {},
   "source": [
    "#### Estimate the cumulative distribution of the equity fractional return for the lattice\n",
    "Finally, we let's draw `number_of_samples` from the categorical distribution `dcat` for each value in the `minimum_return_target_array` array to estimate the probability $P(X\\leq{x})$ using [a `for-loop`](https://docs.julialang.org/en/v1/base/base/#for). \n",
    "\n",
    "For iteration of the loop, we:\n",
    "* Specify a value for the `minimum_target_return,` i.e., this is the minimum level of return that we would accept.\n",
    "* Next, initialize a counter variable `N₊ = 0` and generate `number_of_samples` values for the `random_state_index`, which points to a random category in our set of possible categories (leaves of the binomial tree).\n",
    "* We get the fractional return for the random category, i.e., tree node, and store it in the `random_return_value` variable. We increment the counter variable if the `random_return_value<=minimum_target_return.`\n",
    "* Finally, we estimate the `probability` of having `random_return_value<=minimum_target_return` by computing `N₊/number_of_samples.` We store this in the `length(karray)`$\\times$`2` array `lattice_cumulative_distribution_array,` where the first column is the `minimum_target_return,` and the second column is the `probability.`\n",
    "\n",
    "`Unhide` the code block below to see how we estimated $P(X\\leq{x})$ for each element of the `minimum_return_target_array` array. We store these results in the `lattice_cumulative_distribution_array::Array{Float64,2}` variable, where each row corresponds to a different desired fractional return, the first column in the fractional return $x$, and the second column holds the $P(X\\leq{x})$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4527bce-024d-42db-bca5-c7eb80896c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_cumulative_distribution_array = let\n",
    "\n",
    "    karray = range(0,simulation_stop_index,step = 1) |> collect; # numbering of nodes at L from top to bottom\n",
    "    Sₒ = prediction_dataset[my_ticker_of_interest][simulation_start_index, :volume_weighted_average_price]; # start price\n",
    "    number_of_samples = 25000; # number of samples that we draw from the distribution -\n",
    "    cumulative_distribution_array = Array{Float64,2}(undef, length(karray), 2);\n",
    "    \n",
    "    for i ∈ eachindex(karray)\n",
    "        \n",
    "        minimum_target_return = minimum_return_target_array[i];\n",
    "        \n",
    "        N₊ = 0;\n",
    "        for j ∈ 1:number_of_samples\n",
    "            random_state_index = rand(dcat); #\n",
    "\n",
    "            leaf = leaves[random_state_index];\n",
    "            random_return_value = (leaf.price - Sₒ)/Sₒ\n",
    "            if random_return_value <= minimum_target_return;\n",
    "                N₊ += 1\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        probability = N₊/number_of_samples;     \n",
    "        cumulative_distribution_array[i,1] = minimum_target_return;\n",
    "        cumulative_distribution_array[i,2] = probability;\n",
    "    end\n",
    "\n",
    "    cumulative_distribution_array;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66856b-38fd-404c-9a72-3515a000cbb8",
   "metadata": {},
   "source": [
    "### Cumulative distribution for the GBM model\n",
    "Estimate [the cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function) for the fractional return, i.e., the scaled net present value for `2024` for `my_ticker_of_interest::String` using the GBM models. However, before we can do this, we need to sample the gbm model to produce a set of potential futures that we use to estimate the cumulative probability.\n",
    "\n",
    "To simulate the GBM model, we need to specify the `number_of_samples,` i.e., the number of trajectories to compute, the initial share price `Sₒ,` the initial time `T₁,` the final time `T₂.` Pass these (along with your `model` instance) into the [sample function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.sample-Tuple{MyGeometricBrownianMotionEquityModel,%20NamedTuple}). \n",
    "* The [sample function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.sample-Tuple{MyGeometricBrownianMotionEquityModel,%20NamedTuple}) generates `number_of_samples` possible price trajectories from $T_{1}\\rightarrow{T}_{2}$ using the GBM `model` instance. The simulation data is returned as an array, where the first column in the time and columns `2:end` hold simulated trajectories. Store this in the variable `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f620245-aafd-45f5-93d4-97a787102cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = let \n",
    "    \n",
    "    number_of_samples = 5000; # how many different futures should we simulate\n",
    "    Sₒ = prediction_dataset[my_ticker_of_interest][simulation_start_index, :volume_weighted_average_price]; # start price\n",
    "    model = gbm_model_dictionary[my_ticker_of_interest]; # get model from dictionary\n",
    "\n",
    "    # setup times\n",
    "    T₁ = (simulation_start_index - 1)*Δt # start at simulation_start_index\n",
    "    T₂ = (simulation_stop_index - 1)*Δt # stop at simulation_stop_index\n",
    "    \n",
    "    # sample\n",
    "    X = VLQuantitativeFinancePackage.sample(model, (Sₒ = Sₒ, T₁ = T₁, T₂ = T₂, Δt = Δt), \n",
    "        number_of_paths = number_of_samples);\n",
    "\n",
    "    # return the X \n",
    "    X;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55538a7-c95d-471a-bdb1-bd6494489df2",
   "metadata": {},
   "source": [
    "Now that we have the samples matrix `X,` let's estimate the [the cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function) for fractional return. We'll use the following strategy:\n",
    "* __Strategy__: For each potential hypothetical future (specified by the `number_of_samples::Int64` variable), compute the fraction of these futures that are less than or equal to elements of the `minimum_return_target_array::Array{Float64,1}` array. This gives us an estimate of $P(X\\leq{x})$. In the $P(X\\leq{x})$ expression, big $X$ is a random value (observed fractional return), and $x$ is a specified value (desired fractional return).\n",
    "\n",
    "`Unhide` the code block below to see how we estimated $P(X\\leq{x})$ for each element of the `minimum_return_target_array` array. We store these results in the `gbm_cumulative_probability_array::Array{Float64,2}` variable, where each row corresponds to a different desired fractional return, the first column in the fractional return $x$ and the second column holds the $P(X\\leq{x})$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f0948-a1c3-4986-b171-3b5ba6d0808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_cumulative_probability_array = let\n",
    "\n",
    "    number_of_samples = size(X,2) - 1; # first col is time\n",
    "    number_of_test_points = length(minimum_return_target_array);\n",
    "    cumulative_probability_array = Array{Float64,2}(undef, number_of_test_points, 2);\n",
    "    for i ∈ eachindex(minimum_return_target_array)\n",
    "        test_return = minimum_return_target_array[i];\n",
    "    \n",
    "        N₊ = 0; # How many positive examples do we have?\n",
    "        for j ∈ 1:number_of_samples\n",
    "            Sₒ = X[1,j+1]; # initial share price\n",
    "            S = X[end,j+1]; # final price, col 1 is time\n",
    "            estimate_fractional_return = (S - Sₒ)/Sₒ;\n",
    "\n",
    "            # in this potential future, estimate_fractional_return ≤ test_return?\n",
    "            if (estimate_fractional_return ≤ test_return)\n",
    "                N₊ += 1;\n",
    "            end\n",
    "        end\n",
    "\n",
    "        cumulative_probability_array[i,1] = test_return;\n",
    "        cumulative_probability_array[i,2] = (N₊/number_of_samples);\n",
    "    end\n",
    "\n",
    "    cumulative_probability_array;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391fa30-3cb1-40fd-b6cd-8b0a8b092920",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "`Unhide` the code block below to see how we plotted the estimated $P(X\\leq{x})$ values for the lattice and gbm models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e18108-c014-4e89-ad82-1ccea4759096",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    cprange = range(10,simulation_stop_index-10, step=1) |> collect;\n",
    "    plot(gbm_cumulative_probability_array[cprange,1], gbm_cumulative_probability_array[cprange,2], \n",
    "        c=:blue, lw=2, label=\"GBM $(my_ticker_of_interest) 2024\");\n",
    "    plot!(lattice_cumulative_distribution_array[cprange,1], lattice_cumulative_distribution_array[cprange,2], \n",
    "        c=:red, lw=2, label=\"Lattice $(my_ticker_of_interest) 2024\");\n",
    "    \n",
    "    xlabel!(\"Future fractional return\", fontsize=18)\n",
    "    ylabel!(\"Probability P(X ≤ x) at T = $(simulation_stop_index) days\", fontsize=18)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edccf29-d754-4693-8dc3-8915596c5fee",
   "metadata": {},
   "source": [
    "## Testing\n",
    "In the code block below, we compare your answers to the teaching team and give you feedback on which items are the same (which presumably means they are correct) and which are different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec8691-2110-4223-9dea-b1f1478dbd31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# let\n",
    "#     path_to_soln_file = joinpath(_PATH_TO_SOLN, \"PS3-TeachingTeam-Solution-CHEME-5660-Fall-2024.jld2\"); # set the path to the solution file\n",
    "\n",
    "#     # write the solution file\n",
    "#     save(path_to_soln_file, Dict(\"lattice_model_dictionary\" => lattice_model_dictionary, \n",
    "#             \"gbm_model_dictionary\"=> gbm_model_dictionary,\n",
    "#             \"leaf_probability_array\" => leaf_probability_array,\n",
    "#             \"minimum_return_target_array\" => minimum_return_target_array, \n",
    "#             \"leaves\" => leaves, \"simulation_start_index\" => simulation_start_index, \n",
    "#             \"simulation_stop_index\" => simulation_stop_index, \"Δt\" => Δt,\n",
    "#             \"my_ticker_of_interest\" => my_ticker_of_interest));\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521a869-60fd-4a5b-bb80-c98b832ee48f",
   "metadata": {},
   "source": [
    "__Note__: The checks below will execute for the default settings. As you change the parameters to answer the discussion questions, these will not execute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d08c2-5b49-48af-8188-154b5d9c1313",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "let\n",
    "    # load teaching team solution data -\n",
    "    saved_solution_dict = joinpath(_PATH_TO_SOLN,\"PS3-TeachingTeam-Solution-CHEME-5660-Fall-2024.jld2\") |> load;\n",
    "\n",
    "    if (simulation_stop_index == 62 && my_ticker_of_interest == \"SPY\")\n",
    "        @testset verbose = true \"PS3 Test Suite\" begin\n",
    "            @testset \"checking problem setup\" begin\n",
    "                ticker_soln = saved_solution_dict[\"my_ticker_of_interest\"];\n",
    "                simulation_start_index_soln = saved_solution_dict[\"simulation_start_index\"];\n",
    "                simulation_stop_index_soln = saved_solution_dict[\"simulation_stop_index\"];\n",
    "                Δt_soln = saved_solution_dict[\"Δt\"];\n",
    "    \n",
    "                @test ticker_soln == my_ticker_of_interest\n",
    "                @test simulation_start_index_soln == simulation_start_index;\n",
    "                @test simulation_stop_index_soln == simulation_stop_index;\n",
    "                @test Δt_soln == Δt\n",
    "            end\n",
    "\n",
    "            @testset \"checking lattice model setup\" begin\n",
    "                lattice_model_dictionary_soln = saved_solution_dict[\"lattice_model_dictionary\"];\n",
    "            \n",
    "                # check: SPY -\n",
    "                @test lattice_model_dictionary_soln[\"SPY\"].u == lattice_model_dictionary[\"SPY\"].u\n",
    "                @test lattice_model_dictionary_soln[\"SPY\"].d == lattice_model_dictionary[\"SPY\"].d\n",
    "                @test lattice_model_dictionary_soln[\"SPY\"].p == lattice_model_dictionary[\"SPY\"].p\n",
    "            end\n",
    "\n",
    "            @testset \"checking gbm model setup\" begin\n",
    "                gbm_model_dictionary_soln = saved_solution_dict[\"gbm_model_dictionary\"];\n",
    "            \n",
    "                # check: SPY -\n",
    "                @test gbm_model_dictionary_soln[\"SPY\"].μ == gbm_model_dictionary[\"SPY\"].μ\n",
    "                @test gbm_model_dictionary_soln[\"SPY\"].σ == gbm_model_dictionary[\"SPY\"].σ   \n",
    "            end\n",
    "\n",
    "            @testset \"checking lattice leaf probability values\" begin\n",
    "                leaf_probability_array_soln = saved_solution_dict[\"leaf_probability_array\"];\n",
    "                for i ∈ eachindex(leaf_probability_array_soln)\n",
    "                    @test isapprox(leaf_probability_array_soln[i], leaf_probability_array[i]) \n",
    "                end\n",
    "            end\n",
    "\n",
    "             @testset \"checking lattice leaf price values\" begin\n",
    "                leaves_soln = saved_solution_dict[\"leaves\"];\n",
    "                for i ∈ eachindex(leaves_soln)\n",
    "                    @test isapprox(leaves_soln[i].price, leaves[i].price) \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        println(\"Parameters changed: tests are disabled. Reset to default settings to run tests.\")\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe476f-e646-4d8d-9668-c07f8598e6af",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team. \n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. Such decisions should be based solely on evaluating your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
